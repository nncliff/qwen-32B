{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import string\n",
    "from typing import List, Dict, Tuple\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d60d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_document(num_paragraphs: int = 5, tokens_per_paragraph: int = 10, dim: int = 128) -> List[torch.Tensor]:\n",
    "    \"\"\"Generates a fake document with random sentences.\"\"\"\n",
    "    document = []\n",
    "    for _ in range(num_paragraphs):\n",
    "        base = torch.randn(dim) # shape: (dim,)\n",
    "\n",
    "        # broadcast to create a paragraph\n",
    "        paragraph = base + 0.01 * torch.randn(tokens_per_paragraph, dim) # shape: (tokens_per_paragraph, dim)\n",
    "        \n",
    "        document.append(paragraph)\n",
    "    \n",
    "    return document # List of tensors representing paragraphs of shape (tokens_per_paragraph, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f845e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashIndex:\n",
    "    def __init__(self, key_vectors: List[torch.Tensor], num_buckets: int = 16):\n",
    "        self.buckets: Dict[int, List[Tuple[int, torch.Tensor]]] = {i: [] for i in range(num_buckets)}\n",
    "        self.num_buckets = num_buckets\n",
    "        \n",
    "        for idx, paragraph in enumerate(key_vectors):\n",
    "            # Hash is based on the mean vector of the paragraph\n",
    "            key = paragraph.mean(dim=0)  # the shape of key: (dim,)\n",
    "\n",
    "            bucket_id = self._hash_vector(key) # shape: ()\n",
    "            self.buckets[bucket_id].append((idx, key))\n",
    "\n",
    "    def _hash_vector(self, vector: torch.Tensor) -> int:\n",
    "        \"\"\"Hashes a vector to a bucket ID.\"\"\"\n",
    "        h = hashlib.md5(vector[:3].detach().numpy().tobytes()).hexdigest()  # Use first 3 elements for hashing\n",
    "        return int(h, 16) % self.num_buckets\n",
    "\n",
    "    def search(self, query_vector: torch.Tensor, top_k: int = 3) -> List[int]:\n",
    "        \"\"\"Searches for the top_k closest key vectors to the query_vector.\"\"\"\n",
    "        bucket_id = self._hash_vector(query_vector)\n",
    "        candidates = self.buckets[bucket_id]\n",
    "        scores = []\n",
    "        \n",
    "        for idx, vector in candidates:\n",
    "            # cosine similarity is expecting 2D tensors (batch_size, dim)\n",
    "            # .item() to get scalar value from tensor\n",
    "            dist = F.cosine_similarity(query_vector.unsqueeze(0), vector.unsqueeze(0)).item()\n",
    "            scores.append((idx, dist))\n",
    "        \n",
    "        # Get top_k closest\n",
    "        scores.sort(key=lambda x: x[1])  # Sort by similarity\n",
    "        return [idx for idx, _ in scores[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongDocQA(nn.Module):\n",
    "    def __init__(self, dim: int = 128):\n",
    "        super(LongDocQA, self).__init__()\n",
    "\n",
    "        self.query_encoder = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.answer_decoder = nn.GRU(input_size=dim, hidden_size=dim, batch_first=True)\n",
    "        self.output_proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, query_vector: torch.Tensor, context_vectors: List[torch.Tensor]) -> torch.Tensor:\n",
    "        input_seq = torch.stack(context_vectors, dim=0).unsqueeze(0)  # shape: (1, num_contexts, dim)\n",
    "        _, hidden = self.answer_decoder(input_seq)  # shape: (1, 1, dim)\n",
    "        response = self.output_proj(hidden.squeeze(0))  # shape: (1, dim)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct fake document and index\n",
    "torch.manual_seed(42)\n",
    "dim = 64\n",
    "doc = generate_fake_document(num_paragraphs=30, tokens_per_paragraph=8, dim=dim)\n",
    "#index = HashIndex(doc_summary_vector, num_buckets=8)\n",
    "index = HashIndex(doc, num_buckets=8)\n",
    "\n",
    "# Simulate multiple turns of user queries\n",
    "model = LongDocQA(dim=dim)\n",
    "model.eval()\n",
    "\n",
    "for i in range(1, 6):\n",
    "    # Simulate a user query (main topic and paragraph are relevant)\n",
    "    base_para = random.choice(doc)\n",
    "    query_vector = base_para.mean(dim=0) + 0.02 * torch.randn(dim)  # shape: (dim,)\n",
    "    query_encoded = model.query_encoder(query_vector)  # shape: (dim,)\n",
    "\n",
    "    # Search for relevant paragraphs\n",
    "    top_indices = index.search(query_encoded, top_k=3)\n",
    "    selected_paragraphs = [doc[idx].mean(dim=0) for idx in top_indices]  # List of tensors of shape (dim,)\n",
    "\n",
    "    # Generate answer\n",
    "    with torch.no_grad():\n",
    "        answer_vector = model(query_encoded, selected_paragraphs)  # shape: (dim,)\n",
    "\n",
    "    keywords = ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))\n",
    "    print(f\"Turn {i}: Top paragraphs indices: {top_indices}\")\n",
    "    print(f\"Generate answer summary (norm): {answer_vector.norm().item():.4f} with Answer: {keywords}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
