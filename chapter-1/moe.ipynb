{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "465efaf0",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nncliff/qwen-32B/blob/main/chapter-1/moe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14829e8",
      "metadata": {
        "id": "e14829e8"
      },
      "source": [
        "# Mixture of Experts (MoE) Classifier on CIFAR-10\n",
        "\n",
        "This notebook implements a Mixture of Experts (MoE) classifier using PyTorch on the CIFAR-10 dataset. It is migrated from a standalone Python script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "68d4f2a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68d4f2a0",
        "outputId": "47bb7b29-57c5-40d3-ea12-c05116de23dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e91e58",
      "metadata": {
        "id": "34e91e58"
      },
      "source": [
        "## Mixture of Experts (MoE) Module\n",
        "\n",
        "The `MixtureOfExperts` module is the core component. Here's a breakdown of the tensor shapes during the forward pass:\n",
        "\n",
        "1.  **Input `x`**: `(batch_size, input_dim)`\n",
        "2.  **Gating Network (`self.classifier`)**:\n",
        "    *   Produces logits for each expert.\n",
        "    *   Shape: `(batch_size, num_experts)`\n",
        "3.  **Top-k Selection**:\n",
        "    *   We select the top `k` experts for each sample.\n",
        "    *   `topk_scores`: `(batch_size, k)` - The probabilities of the selected experts.\n",
        "    *   `topk_indices`: `(batch_size, k)` - The indices of the selected experts.\n",
        "4.  **Routing**:\n",
        "    *   We iterate through the `k` selected experts.\n",
        "    *   For each rank `i` (from 0 to k-1), we identify which samples are assigned to which expert.\n",
        "    *   `expert_mask`: `(batch_size, num_experts)` - A boolean mask indicating assignment.\n",
        "5.  **Expert Computation**:\n",
        "    *   For each expert `j`, we select the inputs assigned to it: `expert_input` shape `(num_assigned_samples, input_dim)`.\n",
        "    *   The expert processes these inputs: `expert_out` shape `(num_assigned_samples, input_dim)`.\n",
        "    *   We weight the output by the gating score and add it to the final output.\n",
        "6.  **Output**: `(batch_size, input_dim)` - Same shape as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511b3c21",
      "metadata": {
        "id": "511b3c21"
      },
      "outputs": [],
      "source": [
        "class MixtureOfExperts(nn.Module):\n",
        "    def __init__(self, input_dim, expert_dim, num_experts):\n",
        "        super(MixtureOfExperts, self).__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.expert_dim = expert_dim\n",
        "        self.k = max(1, num_experts // 4)  # Select top-k experts, if k=1, it becomes Top-1 MoE\n",
        "\n",
        "        self.experts = nn.ModuleList([nn.Sequential(\n",
        "            nn.Linear(input_dim, expert_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(expert_dim, input_dim),\n",
        "        ) for _ in range(num_experts)])\n",
        "\n",
        "        self.classifier = nn.Linear(input_dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, input_dim)\n",
        "\n",
        "        # 1. Gating Network: Predict expert weights\n",
        "        logits = self.classifier(x)\n",
        "        # logits shape: (batch_size, num_experts)\n",
        "\n",
        "        topk_scores = F.softmax(logits, dim=1)\n",
        "        # topk_scores shape: (batch_size, num_experts)\n",
        "\n",
        "        # 2. Select Top-k Experts\n",
        "        topk_scores, topk_indices = torch.topk(topk_scores, k=self.k, dim=1)\n",
        "        # topk_scores shape: (batch_size, k)\n",
        "        # topk_indices shape: (batch_size, k)\n",
        "\n",
        "        output = torch.zeros_like(x)\n",
        "        # output shape: (batch_size, input_dim)\n",
        "\n",
        "        # 3. Route inputs to experts\n",
        "        for i in range(self.k):\n",
        "            # Get the i-th selected expert for each sample\n",
        "            expert_idx = topk_indices[:, i]\n",
        "            # expert_idx shape: (batch_size,)\n",
        "\n",
        "            expert_weight = topk_scores[:, i].unsqueeze(1)\n",
        "            # expert_weight shape: (batch_size, 1)\n",
        "\n",
        "            # Create a mask for which expert is selected for which sample at this rank\n",
        "            expert_mask = torch.zeros(x.shape[0], self.num_experts, dtype=torch.bool, device=x.device)\n",
        "            # expert_mask shape: (batch_size, num_experts)\n",
        "\n",
        "            # Set the mask for the selected expert\n",
        "            # The scatter_(dim, index, src) method writes the value src (in this case, True) into the tensor at the indices specified by index along dimension dim.\n",
        "            expert_mask.scatter_(1, expert_idx.unsqueeze(1), True)\n",
        "            # expert_mask is now True at [b, e] if sample b selected expert e as its i-th choice\n",
        "\n",
        "            for j, expert in enumerate(self.experts):\n",
        "                mask = expert_mask[:, j]\n",
        "                # mask shape: (batch_size,) - True if sample assigned to expert j\n",
        "\n",
        "                if mask.any():\n",
        "                    expert_input = x[mask]\n",
        "                    # expert_input shape: (num_assigned_samples, input_dim)\n",
        "\n",
        "                    expert_out = expert(expert_input)\n",
        "                    # expert_out shape: (num_assigned_samples, input_dim)\n",
        "\n",
        "                    # Add weighted expert output to final output\n",
        "                    # We use the mask to place the results back into the correct batch positions\n",
        "                    output[mask] += expert_out * expert_weight[mask]\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "979df92b",
      "metadata": {
        "id": "979df92b"
      },
      "source": [
        "### Example: `scatter_` Operation\n",
        "\n",
        "Let's trace `expert_mask.scatter_(1, expert_idx.unsqueeze(1), True)` with a concrete example.\n",
        "\n",
        "**Setup:**\n",
        "*   **Batch Size**: 3\n",
        "*   **Num Experts**: 5\n",
        "*   **Current Rank**: 1st choice (`i=0`)\n",
        "\n",
        "**1. Initial State:**\n",
        "`expert_mask` is initialized to all zeros (False). Shape `(3, 5)`.\n",
        "```python\n",
        "expert_mask = [\n",
        "    [0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0]\n",
        "]\n",
        "```\n",
        "\n",
        "**2. Expert Indices (`expert_idx`):**\n",
        "Let's say for this rank, the samples selected the following experts:\n",
        "*   Sample 0 -> Expert **1**\n",
        "*   Sample 1 -> Expert **4**\n",
        "*   Sample 2 -> Expert **0**\n",
        "\n",
        "`expert_idx` = `[1, 4, 0]` (Shape: `(3,)`)\n",
        "\n",
        "**3. Unsqueeze:**\n",
        "`expert_idx.unsqueeze(1)` becomes a column vector.\n",
        "```python\n",
        "index = [\n",
        "    [1],\n",
        "    [4],\n",
        "    [0]\n",
        "]\n",
        "```\n",
        "(Shape: `(3, 1)`)\n",
        "\n",
        "**4. Scatter Operation:**\n",
        "`expert_mask.scatter_(dim=1, index=index, src=True)`\n",
        "\n",
        "This tells PyTorch: \"For each row, go to the column specified by `index` and set the value to `True`.\"\n",
        "\n",
        "*   **Row 0**: Index is `1`. Set `expert_mask[0, 1] = True`.\n",
        "*   **Row 1**: Index is `4`. Set `expert_mask[1, 4] = True`.\n",
        "*   **Row 2**: Index is `0`. Set `expert_mask[2, 0] = True`.\n",
        "\n",
        "**5. Final Result:**\n",
        "```python\n",
        "expert_mask = [\n",
        "    [0, 1, 0, 0, 0],  # Sample 0 assigned to Expert 1\n",
        "    [0, 0, 0, 0, 1],  # Sample 1 assigned to Expert 4\n",
        "    [1, 0, 0, 0, 0]   # Sample 2 assigned to Expert 0\n",
        "]\n",
        "```\n",
        "This boolean mask is then used to efficiently select the correct input rows for each expert later in the loop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b4bb981",
      "metadata": {
        "id": "1b4bb981"
      },
      "source": [
        "### Example: `expert_input = x[mask]`\n",
        "\n",
        "Continuing from the previous example, let's see how we select inputs for a specific expert.\n",
        "\n",
        "**Setup:**\n",
        "*   **Input `x`** (Batch Size 3, Input Dim 4):\n",
        "    ```python\n",
        "    x = [\n",
        "        [0.1, 0.1, 0.1, 0.1], # Sample 0\n",
        "        [0.2, 0.2, 0.2, 0.2], # Sample 1\n",
        "        [0.3, 0.3, 0.3, 0.3]  # Sample 2\n",
        "    ]\n",
        "    ```\n",
        "*   **Expert Mask** (from previous step):\n",
        "    ```python\n",
        "    expert_mask = [\n",
        "        [0, 1, 0, 0, 0],  # Sample 0 -> Expert 1\n",
        "        [0, 0, 0, 0, 1],  # Sample 1 -> Expert 4\n",
        "        [1, 0, 0, 0, 0]   # Sample 2 -> Expert 0\n",
        "    ]\n",
        "    ```\n",
        "\n",
        "**Scenario: Loop iteration for Expert 1 (`j=1`)**\n",
        "\n",
        "1.  **Extract Mask Column:**\n",
        "    We look at the column for Expert 1: `mask = expert_mask[:, 1]`.\n",
        "    *   Result: `[True, False, False]` (Sample 0 is True).\n",
        "\n",
        "2.  **Boolean Indexing (`x[mask]`):**\n",
        "    We select the rows from `x` where `mask` is True.\n",
        "    *   Since only the first element is True, we pick the first row of `x`.\n",
        "\n",
        "3.  **Result (`expert_input`):**\n",
        "    ```python\n",
        "    expert_input = [\n",
        "        [0.1, 0.1, 0.1, 0.1]\n",
        "    ]\n",
        "    ```\n",
        "    *   Shape: `(1, 4)` (1 sample assigned, 4 features).\n",
        "    *   This tensor is then passed to Expert 1's neural network.\n",
        "\n",
        "**Scenario: Loop iteration for Expert 2 (`j=2`)**\n",
        "\n",
        "1.  **Extract Mask Column:**\n",
        "    `mask = expert_mask[:, 2]`.\n",
        "    *   Result: `[False, False, False]`.\n",
        "\n",
        "2.  **Check `mask.any()`:**\n",
        "    Since there are no True values, `mask.any()` is False.\n",
        "    *   We **skip** computation for Expert 2 to save resources. No samples need this expert."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "818ec031",
      "metadata": {
        "id": "818ec031"
      },
      "source": [
        "### Explanation: ResNet18 Backbone Modification\n",
        "\n",
        "In the `MoEClassifier` below, you will see these lines:\n",
        "\n",
        "```python\n",
        "self.backbone = torchvision.models.resnet18(pretrained=False)\n",
        "self.backbone.fc = nn.Identity()\n",
        "```\n",
        "\n",
        "**Why do we do this?**\n",
        "\n",
        "1.  **Standard ResNet18**: By default, ResNet18 ends with a fully connected layer (`fc`) that maps features to 1000 classes (for ImageNet).\n",
        "2.  **Feature Extraction**: We want to use ResNet18 only to extract high-level features from the images, not to classify them immediately.\n",
        "3.  **`nn.Identity()`**: By replacing `self.backbone.fc` with `nn.Identity()`, we effectively \"delete\" the classification layer. The data passes through this layer unchanged.\n",
        "4.  **Output Dimension**: The layer immediately preceding the `fc` layer in ResNet18 outputs a vector of size **512**. This 512-dimensional vector serves as the input to our Mixture of Experts module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2eb379a",
      "metadata": {
        "id": "d2eb379a"
      },
      "outputs": [],
      "source": [
        "class MoEClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=512, moe_hidden=1024, num_experts=8, num_classes=10):\n",
        "        super(MoEClassifier, self).__init__()\n",
        "        # ResNet18 backbone\n",
        "        self.backbone = torchvision.models.resnet18(pretrained=False)\n",
        "        self.backbone.fc = nn.Identity()  # Remove the final classification layer\n",
        "        # Output of ResNet18 (without fc) is 512 for standard implementation\n",
        "\n",
        "        self.moe = MixtureOfExperts(input_dim, moe_hidden, num_experts)\n",
        "        self.classifier = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, 3, 224, 224) - Input images\n",
        "\n",
        "        x = self.backbone(x)\n",
        "        # x shape: (batch_size, 512) - Feature vectors from ResNet\n",
        "\n",
        "        x = self.moe(x)\n",
        "        # x shape: (batch_size, 512) - Refined features from MoE\n",
        "\n",
        "        out = self.classifier(x)\n",
        "        # out shape: (batch_size, num_classes) - Class logits\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dfa0462",
      "metadata": {
        "id": "5dfa0462"
      },
      "source": [
        "### Explanation: Data Transformations\n",
        "\n",
        "The `transform` object defines a pipeline of operations to preprocess the images before they are fed into the model.\n",
        "\n",
        "```python\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "```\n",
        "\n",
        "1.  **`transforms.Compose([...])`**: This chains multiple transform steps together. The output of one step becomes the input of the next.\n",
        "2.  **`transforms.Resize((224, 224))`**:\n",
        "    *   **What it does**: Resizes the input image to 224x224 pixels.\n",
        "    *   **Why**: The ResNet18 backbone expects inputs of this size (standard ImageNet size). CIFAR-10 images are originally small (32x32), so we upscale them to match the network's architecture.\n",
        "3.  **`transforms.ToTensor()`**:\n",
        "    *   **What it does**: Converts the image (which is usually a PIL Image or NumPy array with values 0-255) into a PyTorch Tensor.\n",
        "    *   **Normalization**: It also scales the pixel values from the range [0, 255] to [0.0, 1.0].\n",
        "    *   **Channel Ordering**: It changes the dimension order from (Height, Width, Channels) to (Channels, Height, Width), which is the format PyTorch expects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "37c21e99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37c21e99",
        "outputId": "2c87bd91-f9d6-483e-e146-c243b00dc109"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 34.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3200421c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3200421c",
        "outputId": "9883ec34-0753-401f-e438-7311df06208c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = MoEClassifier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3583ce56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3583ce56",
        "outputId": "fd414bf7-14ca-4570-85f3-e186c9ed797a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 1.6121, Accuracy: 39.45%\n",
            "Epoch [2/5], Loss: 1.0392, Accuracy: 62.81%\n",
            "Epoch [3/5], Loss: 0.7854, Accuracy: 72.53%\n",
            "Epoch [4/5], Loss: 0.6135, Accuracy: 78.92%\n",
            "Epoch [5/5], Loss: 0.4960, Accuracy: 82.94%\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "for epoch in range(5):\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/5], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {100.*correct/len(train_loader.dataset):.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
