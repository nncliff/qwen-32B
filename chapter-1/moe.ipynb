{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14829e8",
   "metadata": {},
   "source": [
    "# Mixture of Experts (MoE) Classifier on CIFAR-10\n",
    "\n",
    "This notebook implements a Mixture of Experts (MoE) classifier using PyTorch on the CIFAR-10 dataset. It is migrated from a standalone Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_dim, expert_dim, num_experts):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.expert_dim = expert_dim\n",
    "        self.k = max(1, num_experts // 4)  # Select top-k experts\n",
    "\n",
    "        self.experts = nn.ModuleList([nn.Sequential(\n",
    "            nn.Linear(input_dim, expert_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(expert_dim, input_dim),\n",
    "        ) for _ in range(num_experts)])\n",
    "        \n",
    "        self.classifier = nn.Linear(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the shape of x: \n",
    "        logits = self.classifier(x)\n",
    "        topk_scores = F.softmax(logits, dim=1)\n",
    "\n",
    "        topk_scores, topk_indices = torch.topk(topk_scores, k=self.k, dim=1)\n",
    "        output = torch.zeros_like(x)\n",
    "\n",
    "        for i in range(self.k):\n",
    "            expert_idx = topk_indices[:, i]\n",
    "            expert_weight = topk_scores[:, i].unsqueeze(1)\n",
    "\n",
    "            expert_mask = torch.zeros(x.shape[0], self.num_experts, dtype=torch.bool, device=x.device)\n",
    "            expert_mask.scatter_(1, expert_idx.unsqueeze(1), True)\n",
    "\n",
    "            for j, expert in enumerate(self.experts):\n",
    "                mask = expert_mask[:, j]\n",
    "\n",
    "                if mask.any():\n",
    "                    expert_input = x[mask]\n",
    "                    expert_out = expert(expert_input)\n",
    "                    output[mask] += expert_out * expert_weight[mask]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoEClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=512, moe_hidden=1024, num_experts=8, num_classes=10):\n",
    "        super(MoEClassifier, self).__init__()\n",
    "        self.backbone = torchvision.models.resnet18(pretrained=False)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the final classification layer\n",
    "        self.moe = MixtureOfExperts(input_dim, moe_hidden, num_experts)\n",
    "        self.classifier = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.moe(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c21e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3200421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoEClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(5):\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {100.*correct/len(train_loader.dataset):.2f}%')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
